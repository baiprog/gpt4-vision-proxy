const express = require('express');
const axios = require('axios');
const cors = require('cors');
const app = express();
const port = process.env.PORT;

app.use(cors());
app.use(express.json({ limit: '10mb' }));

// ðŸ“¸ ÐÐ½Ð°Ð»Ð¸Ð· Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
app.post('/analyze', async (req, res) => {
  const { image } = req.body;

  if (!image) {
    return res.status(400).json({ error: 'No image provided' });
  }

  try {
    const response = await axios.post(
      'https://api.openai.com/v1/chat/completions',
      {
        model: 'gpt-4-turbo',
        messages: [
          {
            role: 'user',
            content: [
              {
                type: 'text',
                text: 'Ð§Ñ‚Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¾ Ð½Ð° Ñ„Ð¾Ñ‚Ð¾? ÐÐ°Ð·Ð¾Ð²Ð¸ Ð±Ð»ÑŽÐ´Ð¾, ÐºÐ°Ð»Ð¾Ñ€Ð¸Ð¸ Ð¸ Ð‘Ð–Ð£, ÐµÑÐ»Ð¸ ÑÑ‚Ð¾ ÐµÐ´Ð°.'
              },
              {
                type: 'image_url',
                image_url: { url: image }
              }
            ]
          }
        ],
        max_tokens: 1000
      },
      {
        headers: {
          Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
          'Content-Type': 'application/json'
        }
      }
    );

    res.json(response.data);
  } catch (error) {
    console.error('âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ðº OpenAI:', error.response?.data || error.message);
    res.status(500).json({ error: error.message });
  }
});

// ðŸ§  Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¿Ð»Ð°Ð½Ð° Ð¿Ð¸Ñ‚Ð°Ð½Ð¸Ñ
app.post('/plan', async (req, res) => {
  const { prompt } = req.body;

  if (!prompt) {
    return res.status(400).json({ error: 'No prompt provided' });
  }

  // Ð”Ð˜ÐÐÐœÐ˜Ð§Ð•Ð¡ÐšÐ˜ Ð´Ð¾Ð±Ð°Ð²Ð¸Ð¼ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸ÑŽ Ð´Ð»Ñ ChatGPT
  const planPrompt = `
${prompt}

Ð’ÐÐ–ÐÐž! ÐžÑ‚Ð²ÐµÑ‚ÑŒ ÑÑ‚Ñ€Ð¾Ð³Ð¾ Ð²Ð°Ð»Ð¸Ð´Ð½Ñ‹Ð¼ JSON-Ð¼Ð°ÑÑÐ¸Ð²Ð¾Ð¼ Ð±ÐµÐ· Ð»Ð¸ÑˆÐ½ÐµÐ³Ð¾ Ñ‚ÐµÐºÑÑ‚Ð°, ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸ÐµÐ², Ð¿Ð¾ÑÑÐ½ÐµÐ½Ð¸Ð¹, Ð´Ð¾ Ð¸ Ð¿Ð¾ÑÐ»Ðµ Ð¼Ð°ÑÑÐ¸Ð²Ð°. ÐŸÑ€Ð¸Ð¼ÐµÑ€:
[
  { "time": "Ð—Ð°Ð²Ñ‚Ñ€Ð°Ðº", "name": "ÐžÐ²ÑÑÐ½ÐºÐ° Ñ ÑÐ³Ð¾Ð´Ð°Ð¼Ð¸", "calories": 350, "protein": 15, "fats": 6, "carbs": 60 },
  { "time": "ÐžÐ±ÐµÐ´", "name": "ÐšÑƒÑ€Ð¸Ð½Ð°Ñ Ð³Ñ€ÑƒÐ´ÐºÐ° Ñ Ñ€Ð¸ÑÐ¾Ð¼ Ð¸ Ð¾Ð²Ð¾Ñ‰Ð°Ð¼Ð¸", "calories": 450, "protein": 40, "fats": 10, "carbs": 50 }
]
`;

  try {
    const response = await axios.post(
      'https://api.openai.com/v1/chat/completions',
      {
        model: 'gpt-4',
        messages: [
          {
            role: 'user',
            content: planPrompt
          }
        ],
        max_tokens: 1000,
        temperature: 0.7
      },
      {
        headers: {
          Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
          'Content-Type': 'application/json'
        }
      }
    );

    res.json(response.data);
  } catch (error) {
    console.error('âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¿Ð»Ð°Ð½Ð° Ð¿Ð¸Ñ‚Ð°Ð½Ð¸Ñ:', error.response?.data || error.message);
    res.status(500).json({ error: error.message });
  }
});

// ðŸ’¬ ÐžÐ±Ñ‹Ñ‡Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ñ‡Ð°Ñ‚ Ñ Ð˜Ð˜ (ChatGPT)
app.post('/chat', async (req, res) => {
  const { messages, model = 'gpt-3.5-turbo', max_tokens = 1000, temperature = 0.7 } = req.body;

  if (!messages || !Array.isArray(messages)) {
    return res.status(400).json({ error: 'No messages array provided' });
  }

  try {
    const response = await axios.post(
      'https://api.openai.com/v1/chat/completions',
      {
        model,
        messages,
        max_tokens,
        temperature
      },
      {
        headers: {
          Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
          'Content-Type': 'application/json'
        }
      }
    );

    res.json(response.data);
  } catch (error) {
    console.error('âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ðº OpenAI (Ñ‡Ð°Ñ‚):', error.response?.data || error.message);
    res.status(500).json({ error: error.message });
  }
});

app.listen(port, () => {
  console.log(`âœ… Server is running on port ${port}`);
});
